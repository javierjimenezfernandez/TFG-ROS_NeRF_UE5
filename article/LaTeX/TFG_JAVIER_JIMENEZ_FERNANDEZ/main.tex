% Editor de fórmulas matemáticas
%https://www.codecogs.com/latex/eqneditor.php?lang=es-es

%%%%%%%%%%%%%%%%% - PREÁMBULO - %%%%%%%%%%%%%%%%%


% ---------- Metadatos del documento ----------- %
\title{Digital Twins con control telemático inmersivo mediante el uso de realidad virtual generada por NeRF y 3DGS en tareas de rescate}
\author{Javier Jiménez Fernández}
\date{Septiembre 2024}
% ---------------------------------------------- %


% --------- Composición de la página ---------- %
% Para el texto escrito se utilizará siempre hojas blancas de tamaño A4 (297 x 210 mm) que estarán escritas, preferentemente, por las dos caras. Existen numerosas fuentes válidas aunque se recomienda utilizar “Arial” (tamaño 11 puntos) o “Times New Roman” (tamaño 12 puntos).
\documentclass[a4paper, 12pt, spanish, twoside]{article}
% Los márgenes tanto derecho, como izquierdo, superior e inferior serán de 25 mm.
\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\raggedbottom
% ---------------------------------------------- %



% ------------- Paquetes generales ------------- %
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-tabla]{babel}
\usepackage{float}
\usepackage{caption}
% ---------------------------------------------- %



% ------------ Paquetes específicos ------------ %
\usepackage{pdfpages} % Para insertar la portada en formato PDF.
\usepackage{pdflscape}  % Para colocar páginas en formato apaisado.
\usepackage{graphicx} % Para insertar imágenes.
\graphicspath{{imagenes/}} % Configuración del paquete graphicx, imágenes en la carpeta images
\usepackage{wrapfig} % Para posicionar imágenes alrededor del texto.
\usepackage[hidelinks]{hyperref} % Para urls.
% ---------------------------------------------- %



% ---------------- Numeración ------------------ %
\counterwithin{table}{section} % Se numeran las tablas con respecto al capítulo en el que se encuentran.
\counterwithin{figure}{section} % Se numeran las figuras con respecto al capítulo en el que se encuentran.
\counterwithin{equation}{section} % Se numeran las ecuaciones con respecto al capítulo en el que se encuentran.
% ---------------------------------------------- %



% ------------- Página en blanco ----------------%
% Se define un comando (\blankpage) para insertar una página totalmente en blanco (sin número de página, encabezado y pie de página):
\usepackage{afterpage}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \newpage}
% ---------------------------------------------- %



% ----------- Formato de los párrafos -----------%
% El interlineado recomendado es el sencillo, con renglón libre entre párrafos. El texto debe ser justificado en ambos márgenes, de manera que quede constante la longitud de cada línea del párrafo.
% Se define el formato de los párrafos:
\setlength{\parindent}{0pt} % Se elimina la sangría en comienzo de párrafo (0pt).
\setlength{\parskip}{1em} % Se define el espacio entre dos párrafos (1em).
% ---------------------------------------------- % 



% ---------- Leyendas y pies de foto ----------- %
\captionsetup{justification=centering} % Justificación de las leyendas y pies de foto
% ---------------------------------------------- %



% -------------- Título adicional -------------- %
% Se añade una profundidad adicional a los títulos (profundidad 4):
\usepackage{titlesec}
\setcounter{secnumdepth}{4} % Se fija en 4 la profundidad de numeración de títulos.
\setcounter{tocdepth}{4} % Se fija en 4 la profundidad de títulos incluidos en el índice.
% Se modifica el formato de \paragraph (título de profundidad 4) para adaptarlo al formato del resto de títulos:
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex} 
% ---------------------------------------------- %  



% --------- Encabezado y pie de página -------- %
% Es conveniente la utilización de encabezados y pies de páginas que proporcionen información auxiliar para la mejor lectura y compresión del proyecto, separados del cuerpo del texto por una línea continua y a 15 mm de los márgenes superior e inferior. A título orientativo, en las páginas pares se incluirá en el encabezamiento y justificado a la izquierda el apartado correspondiente (p.ej. Resultados) y en el pie se indicará justificado a la izquierda el número de página y justificado a la derecha “Escuela Técnica Superior de Ingenieros Industriales (UPM)”. En las páginas impares en el encabezamiento figurará justificado a la derecha el título entero del TFG o TFM o un título abreviado para que no exceda de una línea y en el pie se indicará justificado a la izquierda el nombre y apellidos del alumno y justificado a la derecha el número de página.
% El encabezado y pie de página forman parte del paquete fancyhdr:
\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}

% Se ajusta el tamaño de fuente para el encabezado y pie de página (9pt)
\fancyhf{\fontsize{2}{12}\selectfont}

% Contenido del encabezado (\fancyhead):
\fancyhead[RO]{Digital Twins, control telemático y RV generada por NeRF y 3DGS en tareas de rescate} % Texto que se coloca en el encabezado de las páginas impares (O -> 'Odd', o impar) a la izquierda (R -> 'Odd')
\fancyhead[LE]{\nouppercase{\rightmark}} % Texto que se coloca en el encabezado de las páginas pares (E -> 'Even', o par) a la izquierda (L -> 'Left'). \rightmark se utiliza para insertar automáticamente el título de la sección correspondiente, y \nouppercase para que no aparezca todo en mayúsculas (formato por defecto de \rightmark).

% Contenido del pie de página (\fancyfoot):
\fancyfoot[RE]{Escuela  Técnica  Superior  de  Ingenieros  Industriales  (UPM)} % Texto que se coloca en el pie de página de las páginas pares (E -> 'Even', o par) a la derecha (R -> 'Right')
\fancyfoot[LO]{Javier Jiménez Fernández} % Texto que se coloca en el pie de página de las páginas impares (O -> 'Odd', o impar) a la izquierda (L -> 'Left')
\fancyfoot[LE,RO]{\thepage} % El número de página (\thepage) se coloca a la izquierda en las páginas pares y a la derecha en las impares.

% Se indica que sólo se quiere incorporar en \rightmark (utilizado más arriba) el título de la sección (y no de las subsecciones, subsubsecciones, etc.):
\renewcommand{\sectionmark}[1]{\markright{\thesection. #1}}
\renewcommand{\subsectionmark}[1]{}

% Formato de la línea de separación horizontal:
\renewcommand{\headrulewidth}{0.5pt} % Ancho de la línea del encabezado.
\renewcommand{\footrulewidth}{0.5pt} % Ancho de la línea del pie de página.
% ---------------------------------------------- % 



% ----------- Fragmentos de código ------------- %
% El paquete utilizado para insertar fragmentos de código en el documento es listings. En el presente bloque del preámbulo se definen ciertos parámetros de listings con el objetivo de adaptar dicho paquete a código escrito en Python.

\usepackage{listings} % Paquete para insertar código. 
\usepackage{xcolor} % Paquete para definir colores.

% Se definen los distintos colores que se utilizan para resaltar ciertos elementos del código:
\definecolor{codegreen}{rgb}{0.04314,0.6745,0.07843} % Verde.
\definecolor{codegray}{rgb}{0.5,0.5,0.5} % Gris.
\definecolor{codered}{rgb}{0.5373,0.02745,0.06275} % Rojo.
\definecolor{codeblue}{rgb}{0.071,0.0258,0.9882} % Azul.
\definecolor{codepurple}{rgb}{0.6,0.02745,0.5961} % Morado.

% Se define el color de fondo:
\definecolor{backcolour}{rgb}{0.95,0.95,0.92} % Gris oscuro.

% Se define el valor de ciertos parámetros de listings para adaptar dicho paquete a código escrito en Python:
\lstdefinestyle{mystyle}{
    % - General:
    language=C++, % Lenguaje de programación.
    basicstyle=\ttfamily\footnotesize, % Tipografía y tamaño de fuente.
    % - Colores de los distintos elementos del código:
    backgroundcolor=\color{backcolour}, % Color de fondo.  
    commentstyle=\color{codegray}, % Color de los comentarios.
    keywordstyle=\color{codeblue}, % Color de las palabras clave por defecto.
    stringstyle=\color{codegreen}, % Color de los "string"
    % - Palabras clave:
    deletekeywords={print}, % Se elimina "print" del conjunto de palabras clave para posteriormente asignarle el color morado.
    keywordstyle={[2]\ttfamily\color{codeblue}},
    keywords=[2]{as}, % Se añaden las palabras clave de color azul.
    keywordstyle={[3]\ttfamily\color{codepurple}},
    keywords=[3]{True, False, ttk, list, None, dict, zip, range, len, print, float, sum}, % Se añaden las palabras clave de color morado.
    keywordstyle={[4]\bfseries\ttfamily},
    keywords=[4]{_read_excel}, % Se añaden las palabras clave en negrita.
    emph={MyClass,__init__}, % Se añaden las palabras clave enfatizadas.   
    % - Números de línea:
    numberstyle=\tiny\color{codegray}, % Tamaño de fuente y color de los números de línea.
    numbers=left, % Se colocan los números de línea en el lado izquierdo.                 
    numbersep=5pt, % Separación horizontal de los números de línea.
    % - Saltos a la línea, espacios, indentación:
    breaklines=true, % Permitir saltos a la línea. 
    breakatwhitespace=true, % Saltar a la línea únicamente al encontrar espacios.
    postbreak = \mbox{{$\hookrightarrow$}\space}, % Se añade una flecha al cambiar de línea.
    showspaces=false, % No mostrar los espacios. 
    showstringspaces=false, % No mostrar los espacios en los "string".
    keepspaces=true, % Mantener los espacios presentes en el código. 
    tabsize=2, % Tamaño de indentación.
    % - Título:
    captionpos=b % Posición del título del fragmento de código (b=bottom - abajo).
} 
\lstset{style=mystyle} % Se asocia el estilo de listings al estilo que acaba de definirse ("mystyle")

% Se realizan una serie de operaciones complementarias con el paquete listings (su comprensión no es necesaria para manejar dicho paquete):
\makeatletter
\def\lst@OpLiteratekey#1\@nil@{\let\lst@ifxopliterate\lst@if
                             \def\lst@opliterate{#1}}
\lst@Key{opliterate}{}{\@ifstar{\lst@true \lst@OpLiteratekey}
                             {\lst@false\lst@OpLiteratekey}#1\@nil@}
\lst@AddToHook{SelectCharTable}
    {\ifx\lst@opliterate\@empty\else
         \expandafter\lst@OpLiterate\lst@opliterate{}\relax\z@
     \fi}
\def\lst@OpLiterate#1#2#3{%
    \ifx\relax#2\@empty\else
        \lst@CArgX #1\relax\lst@CDef
            {}
            {\let\lst@next\@empty
             \lst@ifxopliterate
                \lst@ifmode \let\lst@next\lst@CArgEmpty \fi
             \fi
             \ifx\lst@next\@empty
                 \ifx\lst@OutputBox\@gobble\else
                   \lst@XPrintToken \let\lst@scanmode\lst@scan@m
                   \lst@token{#2}\lst@length#3\relax
                   \lst@XPrintToken
                 \fi
                 \let\lst@next\lst@CArgEmptyGobble
             \fi
             \lst@next}%
            \@empty
        \expandafter\lst@OpLiterate
    \fi}

\lstset{ 
    literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {Ã}{{\~A}}1 {ã}{{\~a}}1 {Õ}{{\~O}}1 {õ}{{\~o}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\euro}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {º}{{\textordmasculine}}1}

\lstset{opliterate=
   *{0}{{{\color{codered}0}}}1 {1}{{{\color{codered}1}}}1 
   {2}{{{\color{codered}2}}}1 {3}{{{\color{codered}3}}}1 
   {4}{{{\color{codered}4}}}1 {5}{{{\color{codered}5}}}1 
   {6}{{{\color{codered}6}}}1 {7}{{{\color{codered}7}}}1 
   {8}{{{\color{codered}8}}}1 {9}{{{\color{codered}9}}}1}

\DeclareCaptionType{code}[Código][ÍNDICE DE CÓDIGOS] % Se define el entorno "Código" (de forma que al introducir un fragmento de código en el documento aparezca como: Código 1.1: ...), y la lista con los distintos códigos ("Índice de códigos").
\counterwithin{code}{section} % Se numeran los códigos con respecto al capítulo en el que se encuentran.
% ---------------------------------------------- % 



% --------------- Bibliografía ----------------- %
% El manejo de la bibliografía se realiza mediante el paquete biblatex:
\usepackage[backend=biber, style=authoryear, sorting=nyt, citestyle=authoryear, maxcitenames=2, maxbibnames=5, giveninits=true, uniquename=init]{biblatex} 

% Los distintos parámetros que aparecen en la línea anterior corresponden a las siguientes características de la bibliografía:
% - style: la manera en la que aparecen las referencias en la bibliografía. En este caso se opta por "authoryear", pero existen múltiples estilos posibles que se resumen en la siguiente guía: https://www.overleaf.com/learn/latex/biblatex_bibliography_styles.
% - sorting: orden en el que aparecen las distintas referencias en la bibliografía. En este caso se opta por ordenarlas en primer lugar por el apellido del primer autor, en segundo lugar por el año de publicación, y por último por el título de la publicación (nyt=name-year-title)
% - citestyle: elementos y orden de dichos elementos de una referencia al citarla en el documento. En este caso se escoge "authoryear" para que aparezca en primer lugar el apellido del autor (o de los autores) y en segundo lugar el año de publicación. Existe gran variedad de opciones en cuanto al parámetro citestyle que se resumen en: https://www.overleaf.com/learn/latex/biblatex_citation_styles.
% maxcitenames: máximo número de autores que aparecen al citar una referencia en el documento. Al escoger un valor de 2 para este parámetro se pueden dar los siguientes casos: un único autor -> (autor, año), dos autores -> (autor 1 y/e autor 2, año), tres o más autores -> (autor 1 et al., año).
% maxbibnames: parámetro idéntico al anterior pero para la bibliografía en lugar de las citas.
% giveinits y uniquename: para mostrar únicamente las iniciales de los nombres de los autores.

% Se importa el paquete csquotes para citar las referencias a lo largo del documento:
\usepackage{csquotes} 

% Se realizan una serie de operaciones para adaptar la bibliografía al estilo deseado (coma entre autor y año al citar una referencia, idioma castellano, etc.):
\DeclareNameAlias{sortname}{family-given}
\renewcommand*{\nameyeardelim}{\addcomma\space}
\setlength\bibitemsep{\baselineskip}
\DefineBibliographyStrings{spanish}{%
  andothers = {et\addabbrvspace al\adddot}
}

\makeatletter

\newrobustcmd*{\parentexttrack}[1]{%
  \begingroup
  \blx@blxinit
  \blx@setsfcodes
  \blx@bibopenparen#1\blx@bibcloseparen
  \endgroup}

\AtEveryCite{%
  \let\parentext=\parentexttrack%
  \let\bibopenparen=\bibopenbracket%
  \let\bibcloseparen=\bibclosebracket}

\makeatother

\addbibresource{bibliografia.bib}
% ---------------------------------------------- % 


% ----------- Glosario y acrónimos ------------- %
% Para el glosario y los acrónimos, que aparezcan en el índice y que sean una subsubsección
\usepackage[section=subsubsection,acronym,toc]{glossaries}

\makeglossaries
\loadglsentries{glosario}
\loadglsentries{acronimos}

% ---------------------------------------------- %



%%%%%%%%%%%% - INICIO DEL DOCUMENTO - %%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%% - PORTADA - %%%%%%%%%%%%%%%%%%

% Se comienza una página nueva sin formato (sin número de página y sin encabezado/pie de página), ya que sólo incorpora la portada:
\newpage
\thispagestyle{empty}

% La portada se inserta mediante el comando \includepdf seguido del archivo PDF correspondiente (que se ajusta automáticamente a las dimensiones de la página):
\includepdf[landscape]{PORTADA_TFG_JAVIER_JIMENEZ_FERNANDEZ.pdf}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
% La página detrás de la portada va vacía
\blankpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% --------- Numeración primeras páginas -------- %
% Las páginas anteriores al contenido del TFG/TFM (previas a la introducción) suelen numerarse de forma distinta a las del cuerpo del informe, en este caso en números romanos:
\pagenumbering{roman}
% ---------------------------------------------- % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%% - PORTADA CAR - %%%%%%%%%%%%%%%%

\newpage
\thispagestyle{empty}

%\includepdf{}
Aquí va la portada del CAR 

logotipos 

UPM

ETSII

GITI 

Logotipo del CAR 

TFG

Digital Twins con control telemático inmersivo mediante el uso de realidad virtual generada por NeRF y 3DGS en tareas de rescate

Autor: Javier Jiménez Fernández

Tutor Académico: Antonio Barrientos Cruz

Cotutor:  Christyan Mario Cruz Ulloa

Septiembre, 2024

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
% La página detrás de la portada del CAR va vacía
\afterpage{\blankpage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%% - CITA - %%%%%%%%%%%%%%%%%%%%%

% Se comienza una página nueva sin formato (sin número de página y sin encabezado/pie de página), ya que sólo incorpora la cita:
\newpage
\thispagestyle{empty}

\begin{flushright} % Se alinea el texto en el lado derecho de la página.
\vspace*{5cm} % Se añade un espacio vertical de 5cm para situar la cita en ~1/3 de la página.

\textit{“El éxito en la vida no se mide por lo que has logrado, sino por los obstáculos que has superado.”} 

\medskip % Salto a la línea de tamaño medio (existen \smallskip, \medskip y \bigskip)
- Robert Baden-Powell 

\end{flushright}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después de la cita.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%% - AGRADECIMIENTOS - %%%%%%%%%%%%%%%%

% Se comienza una página nueva con formato plano (sin encabezado/pie de página pero con número de página):
\newpage
\thispagestyle{plain}

\section*{AGRADECIMIENTOS} % Se añade un asterisco a \section para que el título no esté numerado.
\addcontentsline{toc}{section}{AGRADECIMIENTOS} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).

Agradezco a \dots

mi madre,
Mandy,
mi amigos,
compañeros de la universidad,
compañeros de trabajo,

Barrientos,
Chrystian,
David,
Jorge,

Fernando Rivas y Volinga

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después de los agradecimientos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%% - CÓMO LEER ESTE DOCUMENTO - %%%%%%%%%%

\section*{CÓMO LEER ESTE DOCUMENTO} % Se añade un asterisco a \section para que el título no esté numerado.
\markright{CÓMO LEER ESTE DOCUMENTO} % Al utilizar \section* se ha de añadir manualmente el título del apartado al encabezado.
\addcontentsline{toc}{section}{CÓMO LEER ESTE DOCUMENTO} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).

En el presente artículo se hace referencia a multitud de términos y acrónimos técnicos específicos. Se anima al lector a hacer uso de las secciones Glosario y Acrónimos durante su lectura.

Por comodidad, se ha realizado una referencia cruzada de todas las menciones a términos y acrónimos definidos en los glosarios. Gracias a ello, en la versión en PDF, clicando sobre sus apariciones a lo largo del documento se redireccionará directamente a su definición. 

Este documento consta de un Resumen Ejecutivo o \textit{abstract} a continuación de esta sección que resume brevemente la investigación de este trabajo. 

Después se encuentra el Índice o tabla general de contenidos y, justo a continuación, se incluyen los Índices de Tablas, Figuras y Códigos de este documento. 

Para seguir, el lector encontrará una Introducción sobre cómo dio comienzo este trabajo, un resumen del Estado del Arte en el campo de la presente investigación, los Objetivos planteados, la Metodología utilizada durante el desarrollo de este trabajo y las Herramientas Utilizadas. 

El grueso del trabajo lo constituyen las secciones de Implementación, Resultados y Conclusiones. En Implementación se incluye todo el camino recorrido por esta investigación hasta llegar al resultado final.

Por último, el lector podrá encontrar la Bibliografía y los Anexos. En los anexos se encuentran la Evaluación de Impactos, la cual incluye la contribución a los Objetivos de Desarrollo Sostenible (ODS), la Planificación temporal y presupuestos, el Glosario y Acrónimos y para terminar las Licencias y términos de uso de las herramientas utilizadas durante esta investigación.

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después de esta sección.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%% - RESUMEN EJECUTIVO - %%%%%%%%%%%%%

\newpage
\section*{RESUMEN EJECUTIVO} % Se añade un asterisco a \section para que el título no esté numerado.
\markright{RESUMEN EJECUTIVO} % Al utilizar \section* se ha de añadir manualmente el título del apartado al encabezado.
\addcontentsline{toc}{section}{RESUMEN EJECUTIVO} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).



\subsection*{Palabras clave} % Se añade un asterisco a \section para que el título no esté numerado.
\addcontentsline{toc}{subsection}{Palabras clave} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).

\subsection*{Códigos UNESCO}
\addcontentsline{toc}{subsection}{Códigos UNESCO} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después del resumen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%% - ÍNDICE - %%%%%%%%%%%%%%%%%%%

\newpage

\renewcommand*\contentsname{ÍNDICE} % Se modifica el nombre por defecto de la "Table Of Contents" (tabla de contenidos, índice) para pasar a llamarla "ÍNDICE".

\tableofcontents % Se genera el índice de contenidos del documento que incorpora todos los títulos de \section, \subsection y \subsubsection (y también \paragraph, ver capítulo 1), así como los títulos añadidos con \addcontentsline (como el resumen ejecutivo, por ejemplo).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después del índice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%% - ÍNDICE DE TABLAS - %%%%%%%%%%%%%%

\newpage

\renewcommand{\listtablename}{ÍNDICE DE TABLAS} % Se define el nombre del índice de tablas.
\listoftables % Se genera automáticamente el índice con las distintas tablas del documento (entorno \table o \longtable).
\addcontentsline{toc}{section}{ÍNDICE DE TABLAS} % Se añade manualmente el apartado al índice (Table Of Contents, TOC).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%% - ÍNDICE DE FIGURAS - %%%%%%%%%%%%%%

\newpage

\renewcommand{\listfigurename}{ÍNDICE DE FIGURAS} % Se define el nombre del índice de figuras.
\listoffigures % Se genera automáticamente el índice con las distintas figuras del documento (entorno \figure).
\addcontentsline{toc}{section}{ÍNDICE DE FIGURAS} % Se añade manualmente el apartado al índice (Table Of Contents, TOC).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%% - ÍNDICE DE CÓDIGOS - %%%%%%%%%%%%%

\newpage

\listofcodes % Se genera automáticamente el índice con los distintos códigos del documento (entorno \code).
\addcontentsline{toc}{section}{ÍNDICE DE CÓDIGOS} % Se añade manualmente el apartado al índice (Table Of Contents, TOC).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage
\afterpage{\blankpage} % Se añade una página en blanco después del índice de códigos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% -------------- Numeración normal ------------- %
% Se inicia una nueva página, y se restablece la numeración de las páginas, utilizando esta vez el sistema de numeración estándar (1, 2, 3, 4, ...)
\newpage
\pagenumbering{arabic}
% ---------------------------------------------- % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%% - INTRODUCCIÓN - %%%%%%%%%%%%%%%%

\newpage
\section{INTRODUCCIÓN} \label{sec:introduccion}

Siempre existe un desencadenante, una chispa, un comienzo. En este caso fue un vídeo de YouTube. En enero de 2022 el divulgador científico sobre \gls{inteligenciaartificial} \href{https://www.youtube.com/@DotCSV}{@DotCSV} habló del recién publicado paper de \gls{nvidia} Developers \gls{nvlabs} \textit{\gls{instant-ngp}} (\cite{mueller2022instant}). El resultado me impresionó tanto que cuando el curso siguiente me acerqué al \acrfull{robcib} buscando un tutor para mi proyecto final de carrera y Christyan me habló sobre generación de entornos 3D para simulación de robots y control telemático con realidad virtual al instante supe que era lo que estaba buscando. Le propuse ser quien probase esta nueva tecnología. 

Así comienza una larga historia pues ni fue mi último año de carrera ni esta nueva tecnología era fácil ni simple de implementar. 

A final del curso 2022/2023 había conseguido probar la tecnología de \gls{instant-ngp}, pero no había conseguido integrarla  de manera satisfactoria con el control de los robots. No lo sabía, pero aún estaba a mitad de camino. Me quedaba madurar más mi investigación y formarme en el uso de nuevas herramientas para llegar al fin donde nos encontramos. 

Hoy me siento orgulloso de lo que he logrado, la paciencia ha dado sus frutos y por fin he hecho el proyecto que quería.  

Tras de mi queda el presente proyecto y toda la documentación para que los que vengan después puedan continuar por este camino.  

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%% - ESTADO DEL ARTE - %%%%%%%%%%%%%%%

\newpage
\section{ESTADO DEL ARTE} \label{sec:estado_del_arte}

El grupo de investigación del \acrfull{robcib} del \acrshort{car} \acrshort{etsii} - \acrshort{upm} lleva a cabo “investigación centrada en el desarrollo de los robots y sus aplicaciones, en particular robots de servicio en exteriores (seguridad, rescate, inspección, agricultura, construcción, etc.). \acrshort{robcib} utiliza tanto robots terrestres como aéreos y aborda técnicas como el GNC (Guiado, Navegación y Control), la inteligencia artificial, la teledetección y las interfaces hombre-máquina aplicadas a sistemas mono y multirobots.” (\cite{robcib}).  

En estos momentos existen diversas líneas de investigación. El presente trabajo se enmarca en el ámbito de las nuevas interfaces hombre-máquina que permiten una colaboración más estrecha y segura entre operadores y robots. 

El punto de partida de esta investigación es, por un lado, tratar de mejorar la interfaz en realidad virtual de los proyectos de control telemático actuales mejorando la sensación de inmersión, y, por otro lado, generar un entorno 3D fotorrealista para la simulación. 

-- capturas de pantalla de la interfaz RV actual y otra de los entornos de simulación actuales 

Es aquí donde entran en juego las tecnologías mencionadas en la introducción y que son objeto de esta investigación. \acrfull{nerf} es una tecnología de \gls{renderizado} de \glspl{radiancefield} en desarrollada en 2020 que pretende resolver el problema de la \gls{funcionplenoptica} en el campo de la visión por computador. 

Desde entonces ha habido una explosión enorme de investigación sobre \acrshort{nerf}. Especialmente destacable en los últimos 2 años ha sido la aparición de \gls{instant-ngp} (\cite{mueller2022instant}), \gls{nerfstudio} (\cite{nerfstudio}) y \acrfull{3dgs} (\cite{kerbl3Dgaussians}). Estas tecnologías han permitido implementar \acrshort{nerf} en gran variedad de sectores generando nuevas áreas de investigación e implementaciones en campos tan diversos como la arquitectura, la robótica, la creación cinematográfica, el diseño de productos o la conducción autónoma. 

-- línea del tiempo con las tecnologías más relevantes relacionadas con NeRF desarrolladas desde 2020 

Según los papers de estas publicaciones, a partir de un conjunto de vistas de una escena en formato de imagen o vídeo (del cual se extraen luego las imágenes) tomadas por un dispositivo cualquiera, una \gls{redneuronal} es capaz de sintetizar nuevas vistas generando un modelo \acrshort{3d} fotorrealista de la escena en un tiempo reducido de segundos. La inmediatez mencionada no siempre es operativamente cierta como se verá más adelante. 

El paper de \acrshort{nerf} fue publicado por primera vez en las \href{https://www.ecva.net/papers.php}{actas de la Conferencia Europea para la Visión por Computador de 2020 (ECCV 2020)}. Como ya se ha comentado, \acrshort{nerf} trata de solucionar el problema de la \gls{funcionplenoptica} en el campo de la visión por computador.  

La pregunta que lleva a la formulación de la \gls{funcionplenoptica} es la siguiente: “¿cuál es el conjunto de todas las cosas que se pueden observar?”. Se trata de una función que busca modelar toda la realidad visual del universo. El campo vectorial de la \gls{funcionplenoptica} permite la “reconstrucción de todas las vistas posibles, en cada momento, desde cada posición, en cada longitud de onda, dentro de los límites de la región espacio-tiempo-longitud de onda considerada” (\cite{adelson:plenoptic}). Así pues, dicha función deberá tener 7 dimensiones:  

\begin{itemize} 
\item 3 coordenadas espaciales $(V_x,V_y,V_z)$ correspondientes al punto desde donde se realiza la observación. 
\item 2 coordenadas angulares $(\theta,\phi)$ correspondientes a la dirección de observación. 
\item 1 coordenada $\lambda$ de longitud de onda. 
\item 1 coordenada temporal $t$.  
\end{itemize} 

Para resolverlo \acrshort{nerf} toma un “campo continuo de 5 dimensiones (localización espacial $(x, y, z)$ y dirección de observación $(\theta, \phi)$)” y representa la escena usando una “red profunda totalmente conectada (no convolucional)” que genera como resultado “la densidad de volumen y la radiancia emitida en función de la dirección de observación para cada localización espacial” (\cite{mildenhall2020nerf}). 

-- imagen funcion de transformación de NeRF 

Es decir, \acrshort{nerf} toma las vistas de la escena junto con la información de las poses de la cámara obtenidas, por ejemplo, mediante fotogrametría y a partir de esta información usa su red neuronal para proyectar los colores y densidades de los puntos en el volumen 3D. De esta forma reconstruye la escena permitiendo observarla desde nuevos puntos de vista. 

-- imagen nerf-pipeline 

\acrshort{nerf} no resuelve la \gls{funcionplenoptica} en sus 7 dimensiones puesto que reduce el problema a un mundo estático. \acrshort{nerf} no incorpora ni la longitud de onda ni la variable temporal. Tampoco calcula todo lo que se podría observar desde cada punto del espacio. Haciendo esto se podría representar cualquier vista desde cualquier parte. En vez de eso, \acrshort{nerf} obtiene el mismo resultado, pero lo hace modelando partículas en cada punto del espacio, su color y radiancia (representada en forma de densidad) que depende del punto y ángulo del observador. 

-- imagen plenoptic vs nerf 

El resultado obtenido se trata de una escena estática compuesta de los valores RGB y densidad ($\sigma$) de las partículas que ocupan puntos concretos del espacio y tiene una representación tridimensional en forma de \gls{nubedepuntos}. Esta \gls{nubedepuntos} es la que compone el \gls{modelo3d} generado por \acrshort{nerf}. 

-- imagen de escenas generadas con NeRF 

La potencia de esta tecnología radica en la capacidad de representar de forma fotorrealista escenas de apariencia y geometría complejas. Es mucho más óptima que la representación de todas las vistas posibles del universo observable que plantea la \gls{funcionplenoptica}, pues obtiene directamente el modelo de la realidad y permite posicionarse en cualquier punto para obtener dichas vistas. Sin embargo, depende del cálculo preciso de las poses de la cámara para las vistas originales. El cálculo de esta fotogrametría es muy costoso computacionalmente y requiere de tiempos desde 30 minutos hasta 2 horas en un ordenador convencional, muy elevados en comparación con el tiempo de generación del\gls{modelo3d}. Este sigue siendo el verdadero cuello de botella de la tecnología \acrshort{nerf} y es la razón por la cual en el transcurso de esta investigación no se ha conseguido operativamente la inmediatez prometida en los papers. 

-- diagrama flujo de trabajo global a grandes rasgos 

A partir de la publicación de \acrshort{nerf} se han conseguido mejoras sustanciales en cuanto a velocidad de entrenamiento y obtención del \gls{modelo3d} con, por ejemplo, \gls{instant-ngp} y de fluidez en la visualización con, por ejemplo, \acrshort{3dgs}. 

\Gls{instant-ngp} es una tecnología desarrollada por \gls{nvidia} Developers \gls{nvlabs} en enero de 2022 y presentada en julio del mismo año. Menos de un año después, en el \gls{nvidia} \acrshort{gtc} de marzo de 2023 se presentaba \gls{nerfstudio}. En las conferencias anuales \gls{nvidia} \acrshort{gtc} se presentan en forma de charlas, sesiones interactivas y \glspl{webinar} las últimas novedades en \acrshort{ia}, cuidados médicos, digitalización industrial y robótica entre otros. Allí no sólo se presentan mejoras de la tecnología como \gls{instant-ngp}, sino también flujos de trabajo, aplicaciones y entornos que ayudan a aplicarlas. Es en la edición de marzo de 2023 cuando Angjoo Kanazawa de la Universidad de Berkeley presentó la herramienta \gls{nerfstudio} que usa el paper de \gls{instant-ngp} (\cite{nerfstudio}) integrado junto con otros métodos bajo el nombre \gls{nerfacto} en un entorno de desarrollo más amable con el usuario. Esta herramienta será de gran utilidad en el presente trabajo. 

-- imagen del diagrama del modelo de Nerfacto 

En julio de 2023 se presenta \acrshort{3dgs}. Una optimización de la nube de puntos obtenida por \gls{instant-ngp} en forma de elementos denominados 3D Gaussians que permite agrupar puntos de representación de la escena evitando cálculos innecesarios en el renderizado en tiempo real durante la visualización de la escena. Se consigue así una gran fluidez en la simulación obteniendo ratios de \acrfull{fps} superiores a 120 \acrshort{fps} para resolución de vídeo de 1080p.  

Recientemente \gls{nerfstudio} también integra la tecnología \acrshort{3dgs} a través de su método \gls{splatfacto} y en colaboración con \gls{volinga} permite su exportación como nube de puntos de alta resolución al motor de gráficos 3D \acrfull{ue}. 

En esta constante ebullición de cambios se mueve la presente investigación. Esto obliga a estar siempre alerta para no dejar de aprovechar las oportunidades que brindan los diferentes enfoques y visiones que proporciona cada nuevo desarrollo. 

% hablar de como se ve esto en la industria audiovisual pero que en realidad surge de un entorno cientifico ? 

% estado del arte de los digital twins ? 

% hablar del estado del arte del control de los robots en el laboratorio? 

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%% - OBJETIVOS - %%%%%%%%%%%%%%%%%%

\newpage
\section{OBJETIVOS} \label{sec:objetivos}

Los modelos \acrshort{3d} de la realidad en los que se simulan los \glspl{digitaltwin} deben aspirar a ser copias lo más fiables posibles del entorno en el que trabajan los robots.  

El objeto de este trabajo es, por un lado, la creación de modelos \acrshort{3d} más realistas que los generados por las herramientas de \gls{fotogrametria} usadas actualmente, especialmente mejorando la resolución y la interpretación de superficies transparentes o reflectantes. Para ello se hará uso de nuevas tecnologías en generación de entornos \acrshort{3d}, como \acrfull{nerf}, \gls{instant-ngp}, \gls{nerfstudio} o \acrfull{3dgs}. 

Por otro lado, también es objeto del presente trabajo ensayar la robustez y el tiempo de despliegue de la tecnología en situaciones de aplicación realistas, así como la compatibilidad con las líneas de investigación actuales del laboratorio \acrfull{robcib} del \acrshort{car} \acrshort{etsii} \acrshort{upm}-\acrshort{csic} en particular la simulación y el control telématico de robots mediante el uso de la \gls{realidadvirtual}. 

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%% - METODOLOGÍA - %%%%%%%%%%%%%%%%%

\newpage
\section{METODOLOGÍA} \label{sec:metodologia}

% Contar bonito que llevo una bitacora y un excel de conteo de horas de trabajo y voy desarrollando manuales de configuración y puesta en marcha de todo lo que voy haciendo por el camino

% Contar también que como es un proyecto de desarrollo de software e implementación de herramientas pues que se hace todo poco a poco y probando la compatibilidad de cada parte con las anteriores. También contar estilo de desarrollo de código y buenas prácticas de programación. 

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%% - HERRAMIENTAS UTILIZADAS - %%%%%%%%%%

\newpage
\section{HERRAMIENTAS UTILIZADAS} \label{sec:herramientas}

% aparte de las obvias (word, excel, ppt, latex, editor de video, etc.)

% Listado de herramientas con su descripción proveniente de la página oficial o paper de turno (va a ser casi todo citar a los autores) 

% ______________ Radiance Fields _______________ %
\subsection{Radiance Fields} \label{sec:herramientas:radfi}

% --------------- Fotogrametría ---------------- %
\subsubsection{Fotogrametría} \label{sec:herramientas:radfi:fotogram}

\paragraph{FFmpeg} \label{sec:herramientas:radfi:fotogram:ffmpeg}
% https://www.ffmpeg.org/

\paragraph{COLMAP} \label{sec:herramientas:radfi:fotogram:colmap}
% https://colmap.github.io/

\paragraph{hloc} \label{sec:herramientas:radfi:fotogram:hloc}
% ---------------------------------------------- %

% -------- Neural Radiance Fields (NeRF) ------- %
\subsubsection{Neural Radiance Fields (NeRF)} \label{sec:herramientas:radfi:nerf}
% https://www.matthewtancik.com/nerf
% https://radiancefields.com/

\paragraph{instant-ngp} \label{sec:herramientas:radfi:nerf:instant-ngp}
% https://nvlabs.github.io/instant-ngp/
% https://github.com/NVlabs/instant-ngp
% https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/

\paragraph{NerfStudio} \label{sec:herramientas:radfi:nerf:nerfstudio}
% https://docs.nerf.studio/
% ---------------------------------------------- %


% -------- 3D Gaussian Splatting (3DGS) -------- %
\subsubsection{3D Gaussian Splatting (3DGS)} \label{sec:herramientas:radfi:3dgs}
% https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/

\paragraph{3DGS (Inria)} \label{sec:herramientas:radfi:3dgs:inria}

\paragraph{NerfStudio} \label{sec:herramientas:radfi:3dgs:nerfstudio}
% ---------------------------------------------- %
% ______________________________________________ %



% ____________ Motores Gráficos 3D _____________ %
\subsection{Motores Gráficos 3D} \label{sec:herramientas:motoresgraficos3d}

% ------------------- Unity -------------------- %
\subsubsection{Unity} \label{sec:herramientas:motoresgraficos3d:unity}
% ---------------------------------------------- %


% ------------- Unreal Engine (UE) ------------- %
\subsubsection{Unreal Engine (UE)} \label{sec:herramientas:motoresgraficos3d:ue}
% ---------------------------------------------- %


% ------------------ Blender ------------------- %
\subsubsection{Blender} \label{sec:herramientas:motoresgraficos3d:blender}
% ---------------------------------------------- %


% ------------------ Volinga ------------------- %
\subsubsection{Volinga} \label{sec:herramientas:motoresgraficos3d:volinga}
% https://docs.nerf.studio/extensions/unreal_engine.html
% https://volinga.ai/
% https://github.com/Volinga/volinga-model
% ---------------------------------------------- %
% ______________________________________________ %



% ______________ Entorno de ROS ________________ %
\subsection{Entorno de ROS} \label{sec:herramientas:entornoros}

% ----------------- VirtualBox ----------------- %
\subsubsection{VirtualBox} \label{sec:herramientas:entornoros:virtualbox}
% ---------------------------------------------- %


% -------- Robot Operating System (ROS) -------- %
\subsubsection{Robot Operating System (ROS)} \label{sec:herramientas:entornoros:ros}
% ---------------------------------------------- %


% --------------- Rosbridge --------------- %
\subsubsection{Rosbridge} \label{sec:herramientas:entornoros:rosbridge}
% ---------------------------------------------- %


% --------------- ROSIntegration --------------- %
\subsubsection{ROSIntegration} \label{sec:herramientas:entornoros:rosintegration}
% ---------------------------------------------- %
% ______________________________________________ %


% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%% - IMPLEMENTACIÓN - %%%%%%%%%%%%%%%

\newpage
\section{IMPLEMENTACIÓN} \label{sec:implementacion}

\subsection{Breve resumen de la implementacion} \label{sec:implementacion:resumen}

En un primer momento se prueba \gls{instant-ngp} a partir del paper de dicha investigación. Se descarta probar el paper original de \acrshort{nerf} pues \gls{instant-ngp} supone tal mejora respecto a tiempos de entrenamiento que no tiene sentido. 

-- comparativa tiempos nerf (12h) vs instant-ngp (max 5min) 

Una vez generado el \gls{modelo3d} como nube de puntos usando \gls{instant-ngp} la exportación fracasa. Se pierde demasiada información en el proceso, no se pueden exportar las ventajas de esta nueva tecnología, así que se descarta este camino y se buscan otras opciones. 

-- imagen del churro mal representado de instant-ngp al exportarlo como mesh visto dentro de Unity 

Se prueba a continuación \gls{nerfstudio}, que usado junto a \gls{volinga} permite generar una nube de puntos exportable a \acrfull{ue} con resultado satisfactorio.  

-- imagen de la nube de puntos dentro de unreal 

A pesar de los buenos resultados esta combinación tiene las siguientes desventajas: 

\begin{itemize} 

\item La nube de puntos no interactúa físicamente con los \gls{actores} dentro de \gls{unrealengine} (por ejemplo, el robot). La sensación visual es como si fuera una bruma, se puede atravesar. 

\item La integración con la realidad virtual no está optimizada, al visualizarlo con las gafas de realidad virtual se ve doble. 

\end{itemize} 

A pesar de ello, se decide seguir adelante con el desarrollo usando esta segunda opción: \gls{nerfstudio}  + \gls{volinga}. 

Se consigue generar un \gls{modelo3d} básico del robot en \acrshort{ue} y controlar su movimiento mediante órdenes de tipo \gls{twist}. Estas órdenes se mandan mediante unas flechas flotantes dentro de la interfaz. 

-- imagen del digital twin y las flechas flotantes 

Se consigue el control del robot real mediante el uso de la herramienta \gls{rosintegration} para \acrshort{ue} en conjunto con \gls{rosbridge} para la conexión con la \gls{maquinavirtual} donde se alojan los nodos de \acrshort{ros}. 

-- imagen del robot real y quizas captura de la máquina virtual 

Más adelante \gls{volinga} lanza una \gls{versionalpha} de su modelo, a la cual esta investigación tiene acceso en exclusiva, en la que se integra la compatibilidad con la realidad virtual. Esta versión es compatible únicamente con \acrshort{3dgs}. 

Se decide probar \acrshort{3dgs} observándose las siguientes diferencias operativas de esta tecnología frente a \gls{instant-ngp}: 

\begin{itemize} 

\item La optimización de la nube de puntos en \glspl{splat} por parte de \acrshort{3dgs} no resulta en modelos tan perfectos como los de \acrshort{nerf}, pues es más sensible a la calidad del \gls{dataset}. Aun así, el \gls{modelo3d} generado es de una calidad satisfactoria. 

-- imagen del entorno generado por 3dgs vs nerfstudio dentro de unreal para el mismo dataset 

\item mientras que el tiempo de entrenamiento de la red neuronal de \gls{instant-ngp} se cuenta en segundos (de 30 segundos a 2 minutos dependiendo del tamaño del modelo), para \acrshort{3dgs} el tiempo se cuenta en minutos (de 15 minutos a 1 hora). 

-- tabla comaparativa de tiempos de entrenamiento de instant-ngp vs nerfstudio vs 3dgs 

\item El rendimiento de los modelos generados por \acrshort{3dgs} es realmente superior a \gls{nerf}. La optimización está bien lograda consiguiendo una fluidez total en su utilización. 

-- tabla o gráficas de fps 3dgs vs otros modelos 

\end{itemize} 

Se decide que esta última es la opción, \acrshort{3dgs} + \gls{volinga}, es la más completa y se decide terminar la implementación con esta configuración. 

 

El conjunto de herramientas elegido finalmente es: 

-- diagrama de bloques del flujo de trabajo final 

\begin{itemize} 

\item \acrshort{3dgs} generado con \gls{nerfstudio} aplicando \gls{volinga-model} en su \gls{versionalpha} compatible con \acrshort{vr} para la generación de la escena 3D. 

-- diagrama detalle de generacion del modelo 3D 

\item \acrlong{ue} con los \gls{plugin} de \gls{volinga} y \gls{rosintegration} para su compatibilidad con la escena generada y con su comunicación con \acrshort{ros}. 

-- diagrama detalle de unreal y rosintegration 

\item La \gls{maquinavirtual} de \gls{ubuntu} con \gls{rosbridge} para la comunicación con su \gls{host} de \gls{windows}, que contiene los nodos necesarios para crear la conexión entre los \glspl{topic} de \acrshort{ue} y el robot real, conectada en modo \acrshort{ros} slave al robot real mediante red Wi-Fi local. 

-- diagrama detalle VM – Wi-Fi – robot  

\end{itemize} 

En las siguientes subsecciones se explica el proceso de implementación con mayor nivel de detalle. 

-- listar subsecciones antes de empezar con ello? 

-- hacer referencia a los manuales (publicarlos en github?) 

\subsection{Instant-ngp de NVIDIA} \label{sec:implementacion:instant-ngp}

\subsubsection{Obtención del modelo 3D de la escena} \label{sec:implementacion:instant-ngp:obtencion}

En primer lugar, se prueba la tecnología que hizo comenzar la presente investigación: \gls{instant-ngp}. Se descarta probar \acrshort{nerf} pues \gls{instant-ngp} supone tal mejora respecto a tiempos de entrenamiento que no tiene sentido.  

-- comparativa tiempos nerf (12h) vs instant-ngp (max 5min) 

Se usa como base el paper original de \gls{instant-ngp} y las instrucciones en el \href{https://github.com/NVlabs/instant-ngp}{repositorio oficial}.  

La puesta en marcha de \gls{instant-ngp} desarrollado por \gls{nvidia} requiere de un entorno con paquete de desarrollo de motor gráfico \acrshort{cuda} 11.8 y toda la configuración que ello conlleva. Se decide crear el entorno en \gls{ubuntu} 18.04 por compatibilidad con \acrshort{ros} y las líneas de investigación actuales del laboratorio. 

Se agregan todos los programas y librerías de dependencias para la instalación de \acrshort{cuda} así como todos los requisitos posteriores a la instalación como por ejemplo la prueba de los \gls{cuda-samples} para verificar su correcto funcionamiento. 

Además, para la obtención de la \gls{fotogrametria} de \glspl{dataset} propios incluida en el flujo de trabajo de \gls{instant-ngp} en su aplicación de Python es necesario un programa externo. Los autores del paper recomiendan la combinación de \gls{ffmpeg}, para la obtención de las vistas a partir de los fotogramas del vídeo, y \gls{colmap}, para calcular para cada vista las poses de la cámara con respecto de la escena. Se instalan y agregan sus dependencias. 

Por último, se descarga el código fuente de \gls{instant-ngp} del \gls{github} de \gls{nvidia} \gls{nvlabs} que es \gls{opensource}. Una vez compilado e instaladas las dependencias ya está listo para usar. 

Para más detalle sobre la instalación ver manual x (-- insertar la referencia). 

Una vez configurado se puede lanzar el script de \Gls{python} proporcionado en el repositorio de \gls{instant-ngp} que transforma el vídeo directamente en su \gls{modelo3d}. El script lanza en primer lugar \gls{ffmpeg} sobre el vídeo para extraer fotogramas formando un \gls{dataset} de imágenes. Una vez extraídas usa \gls{colmap} para obtener la \gls{fotogrametria} de dicho \gls{dataset}.  

-- añadir diagrama del proceso 

La \gls{fotogrametria} junto con el \gls{dataset} de imágenes es el input de la red neuronal de \gls{instant-ngp} que en segundos (entre 30 segundos y un minuto) será capaz de generar un \gls{modelo3d} fotorrealista del objeto o entorno de estudio. 

Por desgracia la generación de la fotogrametría es muy costosa computacionalmente para la \acrshort{gpu} y requiere de largos tiempos dependiendo de la cantidad de imágenes a tratar. El entrenamiento de la red neuronal a partir de la \gls{fotogrametria} y las imágenes también usa la \acrshort{gpu} para sus cálculos, pero es más eficiente generando el \gls{modelo3d}.  

-- tabla comparativa de tiempos de obtención de la fotogrametría para distintos tamaños de dataset 

\textbf{Nota:} los tiempos mostrados son para \gls{dataset} de una calidad suficiente, es decir, que producen un 100\% de match en la herramienta \gls{colmap}. 

Una vez ejecutado el script de \gls{python} para la obtención de la fotogrametría se procede a lanzar la herramienta de \gls{instant-ngp} de \gls{nvidia}. Esta tiene un visor gráfico \acrshort{3d} para observar los resultados del entrenamiento de la red en tiempo real y visualizar cómo en segundos la \gls{nubedepuntos} va convergiendo en el \gls{modelo3d} de nuestro \gls{dataset}.  

-- sucesión de imágenes de cómo se va generando la escena 

-- insertar tablas de velocidades de generación para distintos dataset (tarjeta gráfica vieja) 

Una vez obtenido un resultado aceptable se puede detener el entrenamiento y perfilar el modelo generado, recortando, por ejemplo, la parte deseada del resto de la escena. Además, se puede usar el visualizador para explorar la escena en detalle haciendo zoom sobre las zonas deseadas y así comprobar la calidad del \gls{dataset} y generar uno nuevo si fuera necesario. 

Se debe tener en cuenta que la herramienta \gls{colmap} requiere de una muestra de imágenes nítidas, sin zonas borrosas provocadas por movimientos bruscos durante la toma. Se debe realizar la grabación barriendo la escena lentamente y con una configuración de la cámara adecuada a la iluminación de la escena. 

-- imagen bien tomada vs imagen mal tomada 

Una vez obtenido el \gls{modelo3d}, moverse por dentro del visor 3D para observar la escena desde diferentes ángulos requiere mucha potencia de computación y se experimenta una prácticamente nula fluidez debido a la capacidad de los sistemas disponibles en el laboratorio. Aun así, se comprueba que el modelo generado es de gran calidad y extremadamente fotorrealista. Cabe destacar su capacidad para representar superficies reflectantes o transparentes. 

-- imagen de la representación de una superficie reflectante 

\subsubsection{Exportar el modelo 3D de la escena} \label{sec:implementacion:instant-ngp:exportar}

Una vez seleccionada un área de recorte (que puede incluir la escena entera) se puede exportar la \gls{nubedepuntos} en forma de objeto sólido o \gls{vertexmesh} interpretable por la mayoría de los \gls{motoresgraficos3d} del mercado como \gls{unity} o \gls{unrealengine}. 

La exportación se realiza usando el algoritmo de \gls{marchingcubes} (\cite{lorensen-cline:marchingcubes}), que divide la escena en cubos llamados \glspl{voxel} cuyo tamaño depende de la densidad elegida y para cada \gls{voxel} genera entre 0 y 5 polígonos triangulares que pueden o no compartir aristas. El algoritmo genera los polígonos que mejor se adaptan a la superficie exterior de la nube de puntos. 

-- imagen de los casos fundamentales del algoritmo marching cubes 

Los dos principales problemas de este tipo de exportación de en formato de objeto sólido 3D (.obj) son: 

\begin{itemize} 

\item Para generar los polígonos que conforman las superficies de los objetos de tipo \gls{vertexmesh} a partir de la \gls{nubedepuntos} se requiere una gran capacidad de computación. El \gls{hardware} disponible limita la resolución máxima a la que se puede exportar el objeto, es decir, el número máximo de \glspl{voxel} que contiene, que depende de la capacidad de la \acrshort{gpu}. 
\item La pérdida de la propiedad del color. El estándar del archivo tipo .obj que contiene un \gls{vertexmesh} no incluye información de color, sólo de la posición de los vértices de los polígonos en el interior de cada \glspl{voxel}. Aunque el archivo generado por \gls{instant-ngp} sí guarda información sobre el color, ésta sólo es interpretada por algunos motores gráficos como \gls{meshlab}, pero no por los que se usan en el desarrollo de aplicaciones de robótica. 

\end{itemize} 

Las limitaciones de los ordenadores convencionales impiden una exportación de mayor resolución que implicaría miles de millones de vértices. Para objetos individuales se puede alcanzar una resolución aceptable, pero para una escena como una habitación o una zona exterior la pérdida de información se multiplica, generándose volúmenes que poco se parecen a la realidad. 

-- imagen del churro mal representado de instant-ngp al exportarlo como mesh visto dentro de Unity  

-- añadir también algún ejemplo de visualización mejor por ejemplo del usb de la zapatilla 

Por otro lado, se intenta también la exportación de la nube de puntos de forma directa, sin ningún tipo de tratamiento, pero los motores gráficos compatibles con aplicaciones de robótica no interpretan ese tipo de archivos y se acaba desechando la idea. 

\subsubsection{Mejoras} \label{sec:implementacion:instant-ngp:mejoras}

Debido a la importancia de la potencia de la \acrshort{gpu} en el desempeño de esta investigación, se decide actualizar la tarjeta gráfica del ordenador a una \href{https://es.msi.com/Graphics-Card/GeForce-RTX-2060-VENTUS-12G-OC}{\gls{nvidia} GeForce RTX 2060 VENTUS 12GB OC} del fabricante MSI. También se decide añadir un disco duro \href{https://www.silicon-power.com/web/es/product-Ace_A55}{SP \acrshort{ssd} Ace A55 de 1\acrshort{tb}} para dedicar más espacio a la partición de \gls{ubuntu} 18.04 donde se lleva a cabo todo el flujo de trabajo comentado hasta ahora. Estas modificaciones requieren de la reinstalación de todo el entorno desde cero. 

Las mejoras de hardware producen cambios sustanciales en la velocidad de cálculo de la \gls{fotogrametria} de los \gls{dataset} así como del entrenamiento de la red neuronal para generar el \gls{modelo3d} de la escena. También se experimenta una mejora de la fluidez en el visor 3D de la herramienta pasando de una visualización en 2 \acrshort{fps} al entorno de 5-7 \acrshort{fps}. Sin embargo, no se aprecian mejoras suficientes en la exportación del modelo. 

-- tabla de tiempos de generación del modelo 3d para distintos dataset 

\subsubsection{Evaluación} \label{sec:implementacion:instant-ngp:evaluacion}

La pérdida de resolución y color que se produce durante la exportación hace que el objeto \gls{vertexmesh} obtenido no suponga en la práctica una mejora real con respecto a otros modelos fotogrametría usados anteriormente. Se descarta el uso de \gls{instant-ngp} como herramienta para la generación de entornos 3D para su uso en el control de robots mediante realidad virtual inmersiva. 

-- insertar comparativa fotogrametría antigua vs resultado de exportar instant-ngp. Por ejemplo, se ve similar en cuanto a pataterismo aquí: https://www.youtube.com/watch?v=-1Dz9Izq8Vs min 0:30  

\subsection{NerfStudio + Volinga} \label{sec:implementacion:nerfstudio-volinga}

\subsubsection{Obtención del modelo 3D de la escena} \label{sec:implementacion:nerfstudio-volinga:obtencion}

El propósito de \gls{nerfstudio} es acercar la tecnología \acrshort{nerf} al público general de una manera amable con el usuario. Se trata de una herramienta \gls{opensource} que crea un marco de trabajo modular de fácil integración. Esto simplifica el proceso de crear, entrenar y testear \acrshort{nerf}s (\cite{nerfstudio}). \href{https://docs.nerf.studio/index.html}{Su completa y estructurada web} dispone de \href{https://docs.nerf.studio/quickstart/installation.html}{guía de instalación} así como \href{https://docs.nerf.studio/quickstart/custom_dataset.html}{instrucciones detalladas de cómo usar \glspl{dataset} propios}.  

Para integrar esta opción se elige en un primer momento aprovechar el entorno ya configurado para \gls{instant-ngp} en \gls{ubuntu} 18.04. Siguiendo las guías mencionadas en el párrafo anterior se consigue generar un resultado similar al de \gls{instant-ngp} a partir del mismo \gls{dataset}. 

-- imagenes comparando la misma escena generada por ambos modelos 

El proceso desde el punto de vista del usuario es similar. Se lanza un \gls{script} que primero procesa el archivo de origen para generar un \gls{dataset} de vitas de la escena usando \gls{ffmpeg}. A continuación, el mismo \gls{script} obtiene la fotogrametría de las imágenes con \gls{colmap}. Para terminar, otro \gls{script} usa esa información se para entrenar la \gls{redneuronal} y generar el \gls{modelo3d}.  

-- diagrama del proceso 

La configuración por defecto para el entrenamiento y generación del \gls{modelo3d} de \gls{nerfstudio} se llama \gls{nerfacto} e incluye una combinación de métodos derivados de \acrshort{nerf} de manera que el resultado obtenido es más robusto para toda clase de escenas. 

-- diagrama de nerfacto 

Por ahora se detectan dos grandes diferencias entre \gls{nerfstudio} e \gls{instant-ngp}: 

\begin{itemize} 
\item La sencillez de las instrucciones, requisitos y pasos necesarios para la instalación de \gls{nerfstudio} frente a \gls{instant-ngp}, así como las opciones de personalización del proceso de generación del \gls{modelo3d} haciendo uso de diferentes comandos al lanzar los \glspl{script}. 
\item El visualizador de \gls{nerfstudio} en el navegador web tiene una interfaz mucho más cómoda y amable con el usuario que el visualizador de \gls{instant-ngp}. Además, se visualiza con una fluidez cercana al vídeo convencional a la hora de manejarlo (en torno a 20-24 \acrshort{fps}). 
\end{itemize} 

\subsubsection{Exportar el modelo 3D de la escena} \label{sec:implementacion:nerfstudio-volinga:exportar}

Para poder importar el \gls{modelo3d} a \gls{unrealengine} es necesario entrenar la \gls{redneuronal} con unos parámetros determinados, esto nos permitirá generar los archivos de tipo checkpoint de \gls{nerfstudio} (.ckpt) en un formato compatible con la herramienta \gls{volingasuite}. 

Para ello es necesario instalar el modelo de \gls{volinga} (\gls{volinga-model}) que usará el \gls{script} de \gls{nerfstudio}  durante el entrenamiento para que luego el archivo sea interpretable por el \gls{plugin} de \gls{volinga} dentro de \gls{unrealengine}. En este caso ya no se usará el script de \gls{nerfacto} sino uno específico del modelo de \gls{volinga}. 

-- diagrama del nuevo proceso incluyendo el script de volinga en nerfstudio 

\Gls{volinga-model} es también \gls{opensource} y está disponible para descargar en el \href{https://github.com/Volinga/volinga-model}{repositorio de GitHub de \gls{volinga-model}} puesto a disposición por la compañía. \Gls{volinga-model} es compatible con todo el entorno usado hasta el momento en \gls{ubuntu} 18.04. Se instala para integrarlo en el flujo de trabajo de \gls{nerfstudio}. 

Como ya se ha comentado, \gls{volingasuite} es una aplicación que interpreta los archivos checkpoint de \gls{nerfstudio} (.ckpt) generados mediante el script de \gls{volinga-model} y devuelve un archivo de tipo \gls{nvol} que el \gls{plugin} de \gls{volinga} es capaz de interpretar dentro de \acrshort{ue} para la visualización de la escena generada por \gls{nerfstudio}. 

En el momento de realizar este paso por primera vez (septiembre de 2023) la herramienta de \gls{volingasuite} está en fase de desarrollo y sólo está disponible mediante una \gls{versionbeta} cerrada. Mediante el formulario en su página web se hace una petición de acceso anticipado para su uso en investigación uniersitaria.  

Una vez concedido el acceso se puede usar la herramienta de \gls{volingasuite} tanto en su aplicación de escritorio o directamente a través de su aplicación web. Después de entrenar el \gls{modelo3d} con el script de \gls{volinga-model} se sube el archivo checkpoint de \gls{nerfstudio} (.ckpt) a la aplicación web de \gls{volingasuite}. Ésta genera a su vez el archivo de tipo \gls{nvol} compatible con \gls{unrealengine}. Para la interpretación del archivo \gls{nvol} se requiere la instalación del \gls{plugin} de \gls{volinga} en \acrshort{ue}. 

-- captura de la aplicacion web de volinga con la interfaz de carga de archivos  

Para la instalación de \gls{unrealengine} en \gls{ubuntu} es necesaria la descarga y compilación del código fuente de la aplicación. Para ello se pide acceso al panel de desarrolladores de \gls{unrealengine} en la zona de registro de organizaciones de \gls{github}. Una vez concedido se descarga el código fuente y se genera el entorno de trabajo para \acrshort{ue}. 

La última versión compatible de \acrshort{ue} con \gls{ubuntu} 18.04 (el entorno de \acrshort{nerf}) es la 4.27, pero el \gls{plugin} de \gls{volinga} sólo es compatible con \gls{unrealengine} a partir de la versión 5.0 (\acrshort{ue}5). 

El motor de \acrshort{ue}5 requiere de una versión mínima de \gls{ubuntu} 20.04. por lo que se debe generar de nuevo todo el entorno con la instalación de \acrshort{cuda} 11.8 y las herramientas necesarias para que funcione \gls{nerfstudio} como \gls{colmap} y \gls{ffmpeg}. 

Lamentablemente \acrshort{cuda} 11.8 ya no es compatible con con \gls{ubuntu} 20.04. La versión mínima compatible de los drivers de \gls{nvidia} con \gls{ubuntu} 20.04. es la 525, y \acrshort{cuda} 11.8 requiere de los drivers 520. Por tanto, se decide que, por el momento, el entrenamiento de la red con \gls{nerfstudio} se haga en \gls{ubuntu} 18.04., mientras que la instalación de \acrshort{ue}5 y la posterior integración con \acrshort{ros} se hará en la nueva partición que se ha creado para \gls{ubuntu} 20.04. 

Igualmente surgen problemas al instalar el \gls{plugin} de \gls{volinga} en \acrshort{ue}. Se descubre que éste no soporta un entorno \gls{linux}. 

Por desgracia, al estar la herramienta en desarrollo, la lista de requerimientos mínimos también lo está. Sin embargo, todo tiene su lado positivo y es que esto desencadena una conversación fluida y muy fructífera con los fundadores de la compañía. 

Finalmente se instala \acrshort{ue}5 en \gls{windows} y se mantiene el flujo de trabajo de \gls{nerfstudio} en \gls{ubuntu} 18.04. 

-- diagrama de los dos flujos independientes cada uno en su SO y cómo conecta uno con otro 

Con el \gls{plugin} de \gls{volinga} instalado en \acrshort{ue}5 se puede agregar directamente el objeto \gls{nvol} y visualizar un \gls{modelo3d} muy similar al que se genera en la red neuronal original de \gls{nerfstudio}. Dentro de \acrshort{ue} es necesario el acople de los ángulos de los ejes del \gls{modelo3d} con los del simulador y aplicar el factor de escala necesario.  

Se observa una cierta pérdida de resolución y pequeños fallos en la interpretación de la escena respecto del modelo generado por \gls{instant-ngp}. Esto es debido a pequeñas optimizaciones llevadas a cabo por el script de \gls{volinga} en \gls{nerfstudio} durante el entrenamiento de la red.  

Además, surge un nuevo problema de \gls{hardware}. Se debe al consumo de recursos de computación de la \acrshort{cpu} por parte de \acrshort{ue}. \acrshort{ue} usa la \acrshort{gpu} para el renderizado de gráficos, pero para el cálculo de las sombras, las texturas y la interpretación de la nube de puntos \acrshort{ue} usa la \acrshort{cpu}. Esto hace que la simulación con el ordenador no sea fluida. 

En cualquier caso, el resultado se considera válido ya que supone una mejora enorme en cuanto a realismo respecto a tecnologías previas. 

\subsubsection{Desarrollo del Digital Twin} \label{sec:implementacion:nerfstudio-volinga:desarrollo}

Los \glspl{digitaltwin} disponibles en el laboratorio \acrshort{robcib} están desarrollados en \gls{unity}. Así pues, llegado este punto, hace falta desarrollar un nuevo \gls{gemelodigital} del robot cuadrúpedo \href{https://www.unitree.com/a1/}{Unitree A1} con el que se probará esta tecnología en \gls{unrealengine}. 

Para ello se usa la herramienta \gls{blender} y se utiliza el \href{https://github.com/unitreerobotics/unitree_cad/tree/main/a1}{modelo CAD} proporcionado por la empresa fabricante del robot \href{https://www.unitree.com/}{Unitree Robotics}.  

El \gls{modelocad} contiene las piezas del robot por separado y con \gls{blender} se realiza la unión de éstas mediante un esqueleto o \gls{rig}. El uso de un \gls{rig} permite generar distintas poses para el robot y desarrollar, si se desea, animaciones para su movimiento dentro del \gls{motorgrafico3d}. 

-- imagen del modelo cad en blender con el rig 

Una vez importado el \gls{modelocad} con la pose deseada en \gls{unrealengine} se crea un \gls{actor} dentro del proyecto de \acrshort{ue} al cual se asigna el \gls{mesh} del \gls{modelocad}.  

-- imagen del actor de arturito dentro ue 

El control de dicho \gls{actor} se realiza programando con \glspl{blueprint}. Se crea un \gls{widget} con botones de flechas cuyos eventos de en clicado desencadenan las funciones de los movimientos del robot.  

-- imagen del widget y los blueprint que contiene 

Se demuestra que el robot se puede controlar dentro de la simulación en un proyecto de \acrshort{ue} de simulación con \glspl{blueprint}. 

\subsubsection{ROSIntegration} \label{sec:implementacion:nerfstudio-volinga:rosintegration}

Una vez conseguido lo anterior se intenta la conexión de \acrshort{ue} con \acrshort{ros}.  

\acrshort{ros} es el estándar para aplicaciones de robótica. Está optimizado para funcionar en \gls{ubuntu} y su instalación en \gls{windows} es problemática, es por ello que, para permitir la comunicación entre \acrshort{ue}5 y \acrshort{ros}, se instalará \acrshort{ros} Noetic en \gls{ubuntu} 20.04. en una \gls{maquinavirtual} de \gls{virtualbox} 7 lanzada desde \gls{windows}, donde está \acrshort{ue}.  

-- diagrama 1 comunicación UE con ROS dentro de la máquina virtual (incluir com ssh) 

La conexión con el \gls{host} de \gls{windows} para la configuración de la máquina y lanzar los comandos de \acrshort{ros} se realizará mediante \acrshort{ssh}.  

Para ello se cambiará la configuración de los \glspl{puerto} de la \gls{maquinavirtual} y de la herramienta \acrshort{ssh} dentro de ésta. La conexión \acrshort{ssh} se hace por defecto a través del \gls{puerto} 22, pero es una buena práctica de seguridad no usar el \gls{puerto} reservado por defecto para \acrshort{ssh}. Por tanto, se configurará la conexión a través de un \gls{puerto} no reservado cualquiera (entre el 1024 y el 65536), por ejemplo, el \gls{puerto} 2222. 

-- captura de la conf de puertos de la máquina y del archivo de ssh 

Para que funcione la conexión de \acrshort{ros} con el \gls{host} de \gls{windows} es necesaria la instalación de \gls{rosbridge} en la \gls{maquinavirtual}. \gls{rosbridge} crea una interfaz de tipo \acrshort{json} con \acrshort{ros}, de manera que cualquier \gls{cliente} o \gls{host} conectado con la \gls{maquinavirtual} se pueda suscribir a los \glspl{topic} o llamar a los \glspl{service} de \acrshort{ros}. \gls{rosbridge} soporta la comunicación usando una variedad de protocolos como \gls{websocket} y \acrshort{tcp}. Se decide utilizar el protocolo \acrshort{tcp} a través del \gls{puerto} por convenio para \acrshort{ros}, el 9090. 

-- diagrama detalle comunicación VM con rosbridge 

Para establecer la conexión de \gls{unrealengine} con \gls{rosbridge} se hace uso de una herramienta desarrollada por el \href{https://ai.uni-bremen.de/}{Institute for Artificial Intelligence (IAI) de la Universidad de Bremen} llamada \gls{rosintegration} (\cite{mania19scenarios}). Esta herramienta está diseñada en forma de \gls{plugin} para \gls{unrealengine} 4, pero dicho \gls{plugin} se puede recompilar en un proyecto de \gls{unrealengine} 5 en \gls{cpp} para que funcione correctamente en esta versión. 

\gls{rosintegration} puede utilizar los protocolos \acrshort{tcp} y \gls{websocket} para la comunicación con la \gls{maquinavirtual}. Se usará el protocolo \acrshort{tcp} por compatibilidad con la configuración elegida para \gls{rosbridge}. \gls{rosintegration} conecta \acrshort{ue} con \gls{rosbridge} transmitiendo la información de los \glspl{topic} y \glspl{service} a la interfaz \acrshort{json} por el protocolo \acrshort{tcp} y viceversa. 

-- diagrama completo de la comunicación UE-VM incluyendo rosbridge (interfaz JSON), rosintegration, etc 

El soporte para los principales tipos de mensaje de \acrshort{ros} está completamente implementado en el \gls{plugin} de \gls{rosintegration}. El código para recibir los mensajes de \acrshort{ros} en \acrshort{ue} está completamente desarrollado para su implementación con \glspl{blueprint}. Sin embargo, para el envío desde \acrshort{ue} a \acrshort{ros} sólo está desarrollado el código para mensajes de tipo \Gls{string}.  

Por lo tanto, se desarrolla el código en \gls{cpp} para su cómoda implementación con \glspl{blueprint} dentro de \acrshort{ue}. Este código se compila junto al código fuente del \gls{plugin} de \gls{rosintegration}. 

-- código añadido al plugin de ROSIntegration 

Cuando ya se han configurado todas las herramientas se procede a establecer la conexión entre \acrshort{ue} y \acrshort{ros} en la \gls{maquinavirtual}. Para ello se requiere lanzar \gls{rosbridge} con los parámetros específicos de la conexión con \gls{rosintegration}.  

-- comando específico para dicha conexión 

Una vez establecida la conexión se podrá realizar la subscripción y publicación de los \glspl{topic} o \glspl{service} de \acrshort{ros} que se deseen a ambos lados de la conexión. 

Se comprueba que la subscripción y publicación de \glspl{topic} básicos entre \acrshort{ros} y \acrshort{ue}5 a través de \gls{rosbridge} y \gls{rosintegration} funciona correctamente. 

-- para más info ver el manual en el github 

\subsubsection{Control del Digital Twin desde fuera de UE y transmisión de sus datos} \label{sec:implementacion:nerfstudio-volinga:control}

El ordenador que incorpora el propio robot con sistema operativo \gls{ubuntu} transmite a través de red \acrshort{lan} Wi-Fi y en tiempo real el valor de su \gls{twist} así como la información de su posición respecto del entorno gracias al \acrshort{lidar} que incopora. Todo ello se hace en forma de \glspl{topic} de \acrshort{ros} 

Por ello se elige que la manera de transmitir los cambios de posición entre el robot real y su \gls{gemelodigital} en \acrshort{ue} sea a través del valor de su \gls{twist}. 

Cada vez que se presiona una de las flechas dentro de \acrshort{ue} el \gls{gemelodigital} se mueve o rota en la dirección indicada durante 1 \gls{tick} de \acrshort{ue} a una velocidad de 1m/s. Para equiparar estos valores con los de la realidad se decide que para cada movimiento ordenado al \gls{gemelodigital} dentro del simulador de \acrshort{ue} se enviará durante un tiempo determinado el valor ponderado de su \gls{twist} a la \gls{maquinavirtual} en \acrshort{ros}. Ésta a su vez transmitirá al robot real el \gls{twist} con un valor 10 veces inferior para la velocidad linear y 5 veces inferior para la angular. Estos valores se transmitirán durante 1,5 segundos a una frecuencia de 100Hz, es decir, cada 10ms. Cada movimiento dentro del simulador de \acrshort{ue} se transmitirá de manera secuencial (REVISAR ESTOS VALORES DESPUÉS DE LA NUEVA CALIBRACIÓN) 

-- diagrama de tratamiento de los mensajes de movimiento de UE al robot real 

Cuando el robot se mueve en la realidad ordenado por un mando de control remoto u otro medio ajeno a la simulación en \acrshort{ue}, el \gls{gemelodigital} recibirá el valor del \gls{twist} con un escalado x (POR CALIBRAR) para la velocidad lineal y un escalado y (POR CALIBRAR) para la velocidad angular. 

-- diagrama de tratamiento de los mensajes de movimiento de la realidad a UE 

Estos valores se han calculado de manera empírica para el robot objeto de estudio y su \gls{gemelodigital} en \gls{unrealengine}. 

\subsubsection{Integración del modelo 3D generado por Volinga con el Digital Twin} \label{sec:implementacion:nerfstudio-volinga:integracion}

Para el correcto control del robot en el entorno es necesario el escalado preciso del \gls{modelo3d} generado con \gls{volinga}. Para ello se usa el método del cubo. Este es el método recomendado por los trabajadores de \gls{volinga}. 

La simulación dentro de \acrshort{ue} está milimetrada y sigue una escala del \acrshort{si} en \acrshort{m}. El \gls{digitaltwin} del robot está en escala 1:1 dentro de la simuación respecto de la realidad.  

-- captura del digital twin en modo medicion de distancias de UE 

Para aplicar el método del cubo al \gls{modelo3d} de \gls{volinga} se usan las mediciones del \acrshort{lidar} del robot desplegado en combinación con las imágenes que proporciona su cámara. El \acrshort{lidar} proporciona información de los obstáculos en el plano horizontal a la altura a la que se ubica sobre el robot. Por su parte la cámara del robot toma imágenes desde la parte frontal. 

-- imágenes de dónde se ubican la cámara y el LiDAR en el robot 

-- imágenes de la visión a través del LiDAR y de la cámara. 

Gracias a estos datos el operador localiza dos puntos de referencia de su elección. Estos han de ser visibles tanto en el \gls{modelo3d} como en la realidad, y gracias a la medida precisa del \acrshort{lidar} se genera un cubo dentro de \acrshort{ue} que permitirá el escalado preciso. 

Se procede de la manera siguiente: 

\begin{enumerate} 

\item Se genera un cubo dentro de \acrshort{ue} con una de sus caras paralela al suelo de la escena. 

-- imagen de cubo paralelo al suelo 

\item Se mueve y escala ubicando uno de los dos puntos de referencia sobre una de sus caras y el otro punto sobre la cara opuesta. Estas caras deben elegirse entre las perpendiculares al suelo. 

-- Imagen cubo redimensionado y movido haciendo coincidir los puntos de referencia con dos caras paralelas 

\item Se cambia el tamaño del cubo haciendo coincidir el valor del lado en \acrshort{m} con la medición del \acrshort{lidar}. 

--- imagen redimensionado del cubo con su valor en m 

\item Se ajusta el valor de la escala del \gls{modelo3d} de \gls{volinga} para que los puntos de referencia vuelvan a estar ubicados ambos en las dos caras opuestas del cubo seleccionadas anteriormente. 

-- imagen de la escena redimensionada para coincidir de nuevo con el cubo y la escala aplicada 

\end{enumerate} 

Una vez completado el escalado se simula todo el conjunto para probar su correcto funcionamiento. 

Sin embargo, como ya se comentó al final de la sección (referencia a subsubseccion Exportar el modelo 3D de la escena de esta seccion), existe un problema de consumo de recursos de computación por parte de \acrshort{ue} cuando se visualiza el \gls{modelo3d} generado por \gls{volinga}. Esto hace que la simulación con el ordenador no sea fluida, impidiendo una evaluación correcta del uso conjunto del \gls{digitaltwin} del robot con el \gls{modelo3d} generado por \gls{volinga}. 

\subsubsection{Mejoras} \label{sec:implementacion:nerfstudio-volinga:mejoras}

Para solucionarlo se aplicarán diversas optimizaciones en los gráficos de \acrshort{ue} sugeridas en el foro de Discord de \gls{volinga} como eliminar la parte gráfica del suelo, el Sol y todos los elementos que generan interacciones físicas y de sombras salvo los elementos estrictamente necesarios. Estos son: el \gls{gemelodigital} del robot, la nube de puntos del \gls{modelo3d} generado por \gls{volinga} y un suelo transparente que se hace coincidir con la cota del suelo de la nube de puntos. 

\subsubsection{Evaluación} \label{sec:implementacion:nerfstudio-volinga:evaluacion}

A pesar de las optimizaciones aplicadas no se consigue una simulación suficientemente fluida como para evaluar correctamente el conjunto de tecnologías en estudio. 

\subsection{3DGS + Volinga} \label{sec:implementacion:3dgs-volinga}

\subsubsection{Comparación con NerfStudio + Volinga} \label{sec:implementacion:3dgs-volinga:comparacion}

\acrfull{3dgs} es una tecnología posterior a \gls{instant-ngp} que también usa \glspl{radiancefield} para generar un \gls{modelo3d} de la realidad. Sin embargo, \acrshort{3dgs} se enfoca en mejorar el rendimiento de la visualización de los renderizados respecto a las tecnologías anteriores. \acrshort{3dgs} optimiza los puntos del espacio representados en la nube de puntos en unas figuras gaussianas 3D denominados \glspl{splat} que agrupan zonas enteras de puntos representables con un único objeto y permiten reducir el número de cálculos llevados a cabo para visualizar el modelo. El paper de \acrshort{3dgs} describe cómo la optimización requiere un mayor tiempo de cálculo para generar el \gls{modelo3d}, pero multiplica por 10 la fluidez en la visualización. (\cite{kerbl3Dgaussians}) 

-- gráfico de la web de gaussian splatting comparando el rendimiento de instant-ngp con 3DGS 

El canal de Discord de \gls{volinga} es un foro muy interesante que ha ayudado en el avance de esta investigación en determinados momentos. Llegados a este punto se compartió con el equipo de \gls{volinga} el interés por la realidad virtual y gracias al entendimiento entre ambos equipos se permitió el acceso a una \gls{versionalpha} anticipada del \gls{plugin} de \gls{volinga} optimizado para realidad virtual. 

La \gls{versionalpha} del \gls{plugin} de \gls{volinga} viene con un proyecto de \acrshort{ue} de demostración para poder realizar las pruebas que se deseen sobre él. Se decide comprobar la compatibilidad del \gls{plugin} y la realidad virtual con la implementación del \gls{digitaltwin} llevada a cabo hasta el momento. 

La fluidez de la representación del modelo generado por \acrshort{3dgs} y el \gls{digitaltwin} queda demostrada, así como su control a través de comandos provenientes de \acrshort{ros}. Sin embargo, la interfaz de flechas para el control por parte del operador dentro de \acrshort{ue} no es compatible con la realidad virtual. 

-- imagen de arturito en uno de los dataset de prueba 

Se decide probar a generar un \gls{modelo3d} propio en esta nueva \gls{versionalpha} a partir de los mismos \gls{dataset} usados anteriormente y una vez verificado esto proceder al desarrollo de una nueva interfaz de control para la realidad virtual dentro de \acrshort{ue}. 

La \gls{versionalpha} del \gls{plugin} de \gls{volinga} compatible con \acrshort{vr} sólo acepta como input modelos 3D generados a partir de \gls{3dgaussiansplatting}. Por ello se explora la opción de probar también esta nueva tecnología de generación de modelos 3D a partir de imágenes. 

Los requisitos para el uso de \acrshort{3dgs} son muy similares a los de \acrshort{nerf}. Se estudia si usar el entorno propuesto en el paper original o su implementación en el marco de \gls{nerfstudio} con el método de \gls{splatfacto}. Se elige usar \gls{nerfstudio} por facilidad de integración en el flujo de trabajo actual. 

-- diagrama del flujo de trabajo sustituyendo nerfacto por splatfacto 

Una vez instalado el paquete de \gls{splatfacto} de \gls{nerfstudio} sólo hay que sustituir los comandos de entrenamiento de la red neuronal de \gls{nerfacto} a \gls{splatfacto}. El formato de archivo obtenido ahora es de tipo .ply y es el único input que después de ser procesado por \gls{volingasuite} es compatible con la \gls{versionalpha} del \gls{plugin} de \gls{volinga}. Una vez obtenido el archivo \gls{nvol} por este método, el \gls{plugin} de \gls{volinga} dentro de \acrshort{ue} es capaz de interpretarlo de forma que sea representable en realidad virtual. 

-- nuevo diagrama de obtención del nvol 

Sin embargo, se detecta una precisión inferior a \gls{instant-ngp} a la hora de representar la escena. Debido a las optimizaciones llevadas a cabo por el modelo éste es más sensible a la calidad del \gls{dataset}. Así pues, zonas que \gls{instant-ngp} logra resolver satisfactoriamente \acrshort{3dgs} representa de manera errónea. 

-- mostrar zona superior de la puerta de las calderas instant-ngp vs 3dgs 

A fin de compensar estas carencias existe una serie de herramientas compatibles con el proceso como \acrshort{hloc}. Estas herramientas permiten obtener una fotogrametría más detallada para evitar que las optimizaciones produzcan representaciones erróneas de la realidad. En cualquier caso, la calidad del \gls{dataset} de partida es el factor más relevante a la hora de producir una fotogrametría exacta que resulte en la generación de un \gls{modelo3d} preciso.  

Por tanto, la mejor manera de evitar estas imprecisiones en el modelo es que las imágenes de partida no presenten desperfectos como zonas borrosas o movidas debidas a una mala configuración de la cámara para las condiciones de la escena o un movimiento excesivamente rápido. 

Se compara la obtención de un \gls{modelo3d} usando \acrshort{hloc} en la obtención de la fotogrametría y se compara con el obtenido con el flujo normal de \gls{splatfacto} para el mismo \gls{dataset}. A pesar del uso de \acrshort{hloc} se siguen produciendo interpretaciones erróneas de algunos volúmenes que no ocurrían con \gls{nerfacto}.  

-- imagen de uso de hloc, apenas se aprecia la diferencia 

Aun así, la compatibilidad con la realidad virtual es más relevante que las imprecisiones y se decide trabajar en la interfaz para la realidad virtual. 

\subsubsection{Adaptación de la interfaz para realidad virtual} \label{sec:implementacion:3dgs-volinga:adaptacion}

Para ello se debe modificar la configuración de los \acrfull{imc} de \gls{unrealengine}, así como la configuración para la interacción del \gls{widget} de la interfaz. Para esta configuración resulta imprescindible la colaboración de la comunidad de creadores de videojuegos en YouTube (en especial el siguiente \href{https://www.youtube.com/watch?v=kM27HYbpvc0&lc=Ugw7MlymoPWPie05Jx54AaABAg}{comentario destacado}) ya que se trata de una configuración desactivada recientemente de \gls{unrealengine} sin ninguna información disponible los foros de su extensa comunidad web. 

-- imagen de la configuración de los IMC y del widget para que se pueda interactuar con él  

-- para más detalle ir a mi tutorial en github 

Por comodidad se activa el modo \gls{debug} de manera que se muestren los punteros de los mandos y así facilitar la interacción con la interfaz. 

-- imagen de los punteros 

\subsubsection{Evaluación} \label{sec:implementacion:3dgs-volinga:evaluacion}

Se verifica el funcionamiento de manera fluida de todo el conjunto: 

\begin{itemize} 
\item La implementación y control del \gls{digitaltwin} en \acrshort{ue} 
\item La comunicación con \acrshort{ros} y el robot real 
\item El uso del \gls{modelo3d} generado por \gls{volinga} a partir de Gaussian Splatting 
\item La compatibilidad de todo lo anterior con el entorno de realidad virtual 
\end{itemize} 

\subsection{Buscando los límites de la tecnología 3DGS} \label{sec:implementacion:limites-3dgs}

Debido a la potencia de esta tecnología se desea poner a prueba la capacidad de generación de entornos de la opción \acrshort{3dgs} a partir de \gls{dataset} de imágenes de diferente tipo. 

\subsubsection {Grabaciones con cámara térmica} \label{sec:implementacion:limites-3dgs:termica}

Se comprueba la robustez de la tecnología para generar una escena a partir de imágenes de cámara térmica. 

-- capturas de la escena generada con cámara térmica 

-- enlace al canal de youtube donde se sube el video de la escena 

\subsubsection {Entornos con elementos repetitivos} \label{sec:implementacion:limites-3dgs:repetitivos}

Se comprueba la obtención de escenas en entornos con elementos repetitivos. En este caso la obtención correcta de la escena tiene una mayor dependencia de la calidad del dataset. 

-- capturas de la escena generada por un dataset malo 

-- capturas de la escena generada del car arena 

-- enlace al canal de youtube donde se suben los vídeos de las escenas 

\subsubsection {Elementos de tamaño reducido} \label{sec:implementacion:limites-3dgs:reducido}

Se comprueba la caracterización de objetos pequeños 

-- capturas de la escena generada para el usb de la zapatilla converse 

-- enlace al canal de youtube donde se sube el video de la escena 

\subsubsection {Elementos con geometrías complejas} \label{sec:implementacion:limites-3dgs:complejas}

Se comprueba la caracterización de una rama de diente de león en medio de un entorno lleno de hierba alta. 

-- capturas de la escena generada de la rama 

-- enlace al canal de youtube donde se sube el video de la escena 

\subsubsection {Escenas con reflejos y refracción} \label{sec:implementacion:limites-3dgs:reflejos}

Se comprueba la correcta caracterización de una escena que incluye un acuario y un espejo. 

-- capturas de la escena generada del acuario 

-- enlace al canal de youtube donde se sube el video de la escena 

TBD: 

Ver si se puede probar a usar algo de luma labs (polycam) o Scaniverse (mejor porque está comprobado que usa información del \acrshort{lidar}) en el iPhone Pro de alguien para que la fotogrametría y el escalado se hagan en combinación con el vídeo.  

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%% - RESULTADOS Y DISCUSIÓN - %%%%%%%%%%%

\newpage
\section{RESULTADOS Y DISCUSIÓN} \label{sec:resultados_y_discusion}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%% - CONCLUSIONES - %%%%%%%%%%%%%%%%

\newpage
\section{CONCLUSIONES} \label{sec:conclusiones}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%% - LÍNEAS FUTURAS - %%%%%%%%%%%%%%%

\newpage
\section{LÍNEAS FUTURAS} \label{sec:lineas_futuras}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%% - BIBLIOGRAFÍA - %%%%%%%%%%%%%%%%

\newpage
% Se genera la bibliografía mediante el comando \printbibliography (en ella aparecen únicamente las referencias citadas a lo largo del documento):
\appto{\bibsetup}{\sloppy}
\printbibliography[heading=bibintoc, title=BIBLIOGRAFÍA] % el argumento "title" puede modificarse indicando el título que convenga (bibliografía, referencias, etc.).

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%








%%%%%%%%%%%%%%%%%%% - ANEXOS - %%%%%%%%%%%%%%%%%%%
% FALTA NUMERARLOS Y PONER LOS TÍTULOS EN MINÚSCULAS
% (los índices de tablas, figuras y códigos son anexos y diría que las licencias también)

\newpage

\section*{ANEXOS} \label{sec:anexos} % Se añade un asterisco a \section para que el título no esté numerado.
\addcontentsline{toc}{section}{ANEXOS} % Al utilizar \section* se ha de añadir manualmente el apartado al índice (Table Of Contents, TOC).
\markright{ANEXOS} % Al utilizar \section* se ha de añadir manualmente el título del apartado al encabezado.

\renewcommand{\thesubsection}{\Alph{subsection}} % Se numeran los anexos con letras del alphabeto en lugar de números.
% Se indica que las tablas, figuras y códigos se numeran con el código del anexo (A, B, C, ...) seguido del número de tabla, figura o código dentro del anexo (tabla A.2, figura C.1, etc.)
\renewcommand{\thetable}{\Alph{subsection}.\arabic{table}}
\renewcommand{\thefigure}{\Alph{subsection}.\arabic{figure}}
\renewcommand{\thecode}{\Alph{subsection}.\arabic{code}}

% ---------------- Primer anexo ---------------- %
%%%%%%%%%%% - EVALUACIÓN DE IMPACTOS - %%%%%%%%%%%

\subsection{Anexo I: Evaluación de impactos} \label{sec:anexo1}
\subsubsection{Impacto ambiental} \label{sec:anexo1:ambiental}
\subsubsection{Impacto social} \label{sec:anexo1:social}
\subsubsection{Impacto ético} \label{sec:anexo1:etico}
\subsubsection{Impacto legal} \label{sec:anexo1:legal}
\subsubsection{Contribución a los Objetivos de Desarrollo Sostenible (ODS)} \label{sec:ods}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------------------------------------------- %


% ---------------- Segundo anexo --------------- %
%%% - PLANIFICACIÓN TEMPORAL Y PRESUPUESTOS - %%%%

\newpage
\subsection{Anexo II: Planificación temporal y presupuestos} \label{sec:anexo2}
\subsubsection{Planificación temporal} \label{sec:anexo2:temporal}
\subsubsection{Presupuestos} \label{sec:anexo2:presupuestos}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------------------------------------------- %


% ---------------- Tercer anexo ---------------- %
%%%%%%%%%%%% - GLOSARIO Y ACRÓNIMOS - %%%%%%%%%%%%

\newpage
\subsection{Anexo III: Glosario y acrónimos} \label{sec:anexo3}

\glsaddall

% Hacer más grande el tamaño del título de la subsubseccion glosario y acronimos
%\renewcommand{\subsubsectionsize}{\large}

\printglossary[title=Glosario, toctitle=Glosario]

\newpage
\printglossary[type=\acronymtype, title={Abreviaturas, unidades y acrónimos}, toctitle={Abreviaturas, unidades y acrónimos}]

%\renewcommand{\subsubsectionsize}{\normal}

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------------------------------------------- %


% ---------------- Cuarto anexo ---------------- %
%%%%%%%%%%%%%%%%% - LICENCIAS - %%%%%%%%%%%%%%%%%%

\newpage
\subsection{Anexo IV: Licencias} \label{sec:anexo4}

Toda la presente investigación ha sido llevada a cabo de acuerdo con las siguientes licencias y términos de uso.

Licencia de 3DGS: https://github.com/graphdeco-inria/gaussian-splatting/blob/main/LICENSE.md

Licencia de Blender: 

Licencia de COLMAP: https://colmap.github.io/license.html

Licencia de FFmpeg: https://www.ffmpeg.org/legal.html

Licencia de GitHub: 

Licencia de GitKraken: 

Licencia de hloc: https://github.com/cvg/Hierarchical-Localization/blob/master/LICENSE

Licencia de instant-ngp: https://github.com/NVlabs/instant-ngp/blob/master/LICENSE.txt y al final de https://github.com/NVlabs/instant-ngp

Licencia de NeRF: https://github.com/bmild/nerf/blob/master/LICENSE

Licencia de NerfStudio: https://github.com/nerfstudio-project/nerfstudio/blob/main/LICENSE

Licencia ODS (ONU): https://www.un.org/es/about-us/terms-of-use

Licencia de ROS: 

Licencia de ROSIntegration: https://github.com/code-iai/ROSIntegration/blob/master/LICENSE

Licencia de Ubuntu: 

Licencia de Unity: 

Licencia de Unreal Engine: 

Licencia de VirtualBox: 

Licencia de Volinga: https://volinga.ai/ (see "Terms of use" at the bottom of the webpage)

Licencia de VSCode: 

Licencia de Windows: 

\begin{wrapfigure}{L}{0.23\textwidth}
    \vspace{-\baselineskip}
    \href{http://creativecommons.org/licenses/by/4.0/}{\includegraphics[width=0.22\textwidth]{licencias/cc-by.png}}
\end{wrapfigure} 

%\vspace*{\fill}
``Plantilla en LaTeX acorde con la Normativa para la elaboración de informes de TFT de la ETSII (UPM)" \ by Javier Soto Pérez-Olivares is licensed under a \href{http://creativecommons.org/licenses/by/4.0/}{Creative Commons Attribution 4.0 International License}.

% Termina la página actual y hace que se impriman todas las figuras y tablas que han aparecido hasta ahora en la entrada:
\clearpage

% ---------------------------------------------- % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---------------------------------------------- %


%%%%%%%%%%%%%% - FIN DEL DOCUMENTO - %%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%